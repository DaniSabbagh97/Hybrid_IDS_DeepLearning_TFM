{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60659b5c",
   "metadata": {},
   "source": [
    "# Interpretabilidad Pipe1/Pipe2/Pipe3 (FP/FN/TP/TN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004656bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_test_preds.parquet -> ['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack']\n",
      "     pipeline           timestamp  y_true  y_pred  p_attack\n",
      "0  p1_pca_mlp 2017-07-07 03:23:00       1       1  0.962043\n",
      "1  p1_pca_mlp 2017-07-07 03:23:00       1       1  0.962855 \n",
      "\n",
      "p2_test_preds.parquet -> ['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack', 'window_start', 'window_end', 'window_size', 'stride']\n",
      "         pipeline           timestamp  y_true  y_pred  p_attack  window_start  \\\n",
      "0  p2_pca_gru_tcn 2017-07-07 03:23:00       1       1  0.679983             0   \n",
      "1  p2_pca_gru_tcn 2017-07-07 03:23:00       1       1  0.902339             5   \n",
      "\n",
      "   window_end  window_size  stride  \n",
      "0          19           20       5  \n",
      "1          24           20       5   \n",
      "\n",
      "p3_test_preds.parquet -> ['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack', 'window_start', 'window_end', 'window_size', 'stride']\n",
      "             pipeline           timestamp  y_true  y_pred  p_attack  \\\n",
      "0  p3_pca_transformer 2017-07-07 03:23:00       1       0  0.000650   \n",
      "1  p3_pca_transformer 2017-07-07 03:23:00       1       0  0.000217   \n",
      "\n",
      "   window_start  window_end  window_size  stride  \n",
      "0             0          19           20       5  \n",
      "1             5          24           20       5   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for f in [\"p1_test_preds.parquet\", \"p2_test_preds.parquet\", \"p3_test_preds.parquet\"]:\n",
    "    dfp = pd.read_parquet(f)\n",
    "    print(f, \"->\", dfp.columns.tolist())\n",
    "    print(dfp.head(2), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea80add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1: (424581, 5) Index(['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack'], dtype='object')\n",
      "p2: (84913, 9) Index(['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack', 'window_start',\n",
      "       'window_end', 'window_size', 'stride'],\n",
      "      dtype='object')\n",
      "p3: (84913, 9) Index(['pipeline', 'timestamp', 'y_true', 'y_pred', 'p_attack', 'window_start',\n",
      "       'window_end', 'window_size', 'stride'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "EXPORT_DIR = \"exports\"\n",
    "\n",
    "p1 = pd.read_parquet(f\"p1_test_preds.parquet\")\n",
    "p2 = pd.read_parquet(f\"p2_test_preds.parquet\")\n",
    "p3 = pd.read_parquet(f\"p3_test_preds.parquet\")\n",
    "\n",
    "print(\"p1:\", p1.shape, p1.columns)\n",
    "print(\"p2:\", p2.shape, p2.columns)\n",
    "print(\"p3:\", p3.shape, p3.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7da3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== P1 ===\n",
      "Confusion:\n",
      " [[294124     33]\n",
      " [  1342 129082]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9955    0.9999    0.9977    294157\n",
      "           1     0.9997    0.9897    0.9947    130424\n",
      "\n",
      "    accuracy                         0.9968    424581\n",
      "   macro avg     0.9976    0.9948    0.9962    424581\n",
      "weighted avg     0.9968    0.9968    0.9968    424581\n",
      "\n",
      "\n",
      "=== P2 ===\n",
      "Confusion:\n",
      " [[55465  3361]\n",
      " [  362 25725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9935    0.9429    0.9675     58826\n",
      "           1     0.8844    0.9861    0.9325     26087\n",
      "\n",
      "    accuracy                         0.9562     84913\n",
      "   macro avg     0.9390    0.9645    0.9500     84913\n",
      "weighted avg     0.9600    0.9562    0.9568     84913\n",
      "\n",
      "\n",
      "=== P3 ===\n",
      "Confusion:\n",
      " [[57961   865]\n",
      " [  686 25401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9883    0.9853    0.9868     58826\n",
      "           1     0.9671    0.9737    0.9704     26087\n",
      "\n",
      "    accuracy                         0.9817     84913\n",
      "   macro avg     0.9777    0.9795    0.9786     84913\n",
      "weighted avg     0.9818    0.9817    0.9818     84913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def standardize_cols(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    \n",
    "    # prob ataque (acepta varios nombres)\n",
    "    prob_candidates = [\"p_attack\", \"prob_attack\", \"proba_attack\", \"y_prob_attack\", \"p1\", \"prob1\"]\n",
    "    prob_col = None\n",
    "    for c in prob_candidates:\n",
    "        if c in df.columns:\n",
    "            prob_col = c\n",
    "            break\n",
    "\n",
    "    df = df.rename(columns={prob_col: \"p_attack\"})\n",
    "    return df\n",
    "\n",
    "def add_fp_fn(df):\n",
    "    df = df.copy()\n",
    "    df[\"FP\"] = ((df[\"y_true\"] == 0) & (df[\"y_pred\"] == 1)).astype(int)\n",
    "    df[\"FN\"] = ((df[\"y_true\"] == 1) & (df[\"y_pred\"] == 0)).astype(int)\n",
    "    df[\"TP\"] = ((df[\"y_true\"] == 1) & (df[\"y_pred\"] == 1)).astype(int)\n",
    "    df[\"TN\"] = ((df[\"y_true\"] == 0) & (df[\"y_pred\"] == 0)).astype(int)\n",
    "    return df\n",
    "\n",
    "def quick_report(name, df):\n",
    "    cm = confusion_matrix(df[\"y_true\"], df[\"y_pred\"])\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Confusion:\\n\", cm)\n",
    "    print(classification_report(df[\"y_true\"], df[\"y_pred\"], digits=4))\n",
    "\n",
    "p1s = add_fp_fn(standardize_cols(p1))\n",
    "p2s = add_fp_fn(standardize_cols(p2))\n",
    "p3s = add_fp_fn(standardize_cols(p3))  \n",
    "\n",
    "quick_report(\"P1\", p1s)\n",
    "quick_report(\"P2\", p2s)\n",
    "quick_report(\"P3\", p3s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc768c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 days: [datetime.date(2017, 7, 7)]\n",
      "P2 days: [datetime.date(2017, 7, 7)]\n",
      "P3 days: [datetime.date(2017, 7, 7)]\n"
     ]
    }
   ],
   "source": [
    "def ensure_timestamp(df):\n",
    "    df = df.copy()\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df[\"day\"] = df[\"timestamp\"].dt.date\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    return df\n",
    "\n",
    "p1t = ensure_timestamp(p1s)\n",
    "p2t = ensure_timestamp(p2s)\n",
    "p3t = ensure_timestamp(p3s)\n",
    "\n",
    "print(\"P1 days:\", np.unique(p1t[\"day\"]))\n",
    "print(\"P2 days:\", np.unique(p2t[\"day\"]))\n",
    "print(\"P3 days:\", np.unique(p3t[\"day\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57f5a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1:\n",
      "           day  FP    FN      TP      TN       n   FP_rate  FN_rate\n",
      "0  2017-07-07  33  1342  129082  294124  424581  0.000112  0.01029\n",
      "\n",
      "P2:\n",
      "           day    FP   FN     TP     TN      n   FP_rate   FN_rate\n",
      "0  2017-07-07  3361  362  25725  55465  84913  0.057135  0.013877\n",
      "\n",
      "P3:\n",
      "           day   FP   FN     TP     TN      n   FP_rate   FN_rate\n",
      "0  2017-07-07  865  686  25401  57961  84913  0.014704  0.026297\n"
     ]
    }
   ],
   "source": [
    "def fpfn_by_day(df):\n",
    "    g = df.groupby(\"day\")[[\"FP\",\"FN\",\"TP\",\"TN\"]].sum().reset_index()\n",
    "    g[\"n\"] = df.groupby(\"day\").size().values\n",
    "    g[\"FP_rate\"] = g[\"FP\"] / (g[\"FP\"] + g[\"TN\"]).replace(0, np.nan)\n",
    "    g[\"FN_rate\"] = g[\"FN\"] / (g[\"FN\"] + g[\"TP\"]).replace(0, np.nan)\n",
    "    return g\n",
    "\n",
    "d1 = fpfn_by_day(p1t)\n",
    "d2 = fpfn_by_day(p2t)\n",
    "d3 = fpfn_by_day(p3t)\n",
    "\n",
    "print(\"P1:\\n\", d1)\n",
    "print(\"\\nP2:\\n\", d2)\n",
    "print(\"\\nP3:\\n\", d3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d887c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 hour head:\n",
      "    hour  FP  FN      TP     TN       n   FP_rate   FN_rate\n",
      "0     3  23  56   24240  35987   60306  0.000639  0.002305\n",
      "1     4   0  52  104110  67530  171692  0.000000  0.000499\n",
      "2     5   0   0       0   1552    1552  0.000000       NaN\n",
      "3     8   0   0       0      2       2  0.000000       NaN\n",
      "4     9   0   1       1  49981   49983  0.000000  0.500000\n",
      "\n",
      "P2 hour head:\n",
      "    hour    FP   FN     TP     TN      n   FP_rate   FN_rate\n",
      "0     3   568   12   4843   6635  12058  0.078856  0.002472\n",
      "1     4  2447   23  20802  11066  34338  0.181085  0.001104\n",
      "2     5     2    0      0    309    311  0.006431       NaN\n",
      "3     9   115    0      1   9881   9997  0.011505  0.000000\n",
      "4    10   135  239     59  13881  14314  0.009632  0.802013\n",
      "\n",
      "P3 hour head:\n",
      "    hour   FP   FN     TP     TN      n   FP_rate   FN_rate\n",
      "0     3  138  176   4679   7065  12058  0.019159  0.036251\n",
      "1     4  579  103  20722  12934  34338  0.042848  0.004946\n",
      "2     5    3    0      0    308    311  0.009646       NaN\n",
      "3     9   38    1      0   9958   9997  0.003802  1.000000\n",
      "4    10   55  298      0  13961  14314  0.003924  1.000000\n"
     ]
    }
   ],
   "source": [
    "def fpfn_by_hour(df):\n",
    "    g = df.groupby(\"hour\")[[\"FP\",\"FN\",\"TP\",\"TN\"]].sum().reset_index()\n",
    "    g[\"n\"] = df.groupby(\"hour\").size().values\n",
    "    g[\"FP_rate\"] = g[\"FP\"] / (g[\"FP\"] + g[\"TN\"]).replace(0, np.nan)\n",
    "    g[\"FN_rate\"] = g[\"FN\"] / (g[\"FN\"] + g[\"TP\"]).replace(0, np.nan)\n",
    "    return g.sort_values(\"hour\")\n",
    "\n",
    "h1 = fpfn_by_hour(p1t)\n",
    "h2 = fpfn_by_hour(p2t)\n",
    "h3 = fpfn_by_hour(p3t)\n",
    "\n",
    "print(\"P1 hour head:\\n\", h1.head())\n",
    "print(\"\\nP2 hour head:\\n\", h2.head())\n",
    "print(\"\\nP3 hour head:\\n\", h3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8964df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3 - top FP:\n",
      "                 timestamp  y_true  y_pred  p_attack\n",
      "39771 2017-07-07 04:15:00       0       1  0.999897\n",
      "12172 2017-07-07 04:00:00       0       1  0.999863\n",
      "39770 2017-07-07 04:15:00       0       1  0.999819\n",
      "14545 2017-07-07 04:01:00       0       1  0.999767\n",
      "45180 2017-07-07 04:51:00       0       1  0.999752\n",
      "8910  2017-07-07 03:58:00       0       1  0.999728\n",
      "14544 2017-07-07 04:01:00       0       1  0.999720\n",
      "21424 2017-07-07 04:05:00       0       1  0.999692\n",
      "21422 2017-07-07 04:05:00       0       1  0.999669\n",
      "21429 2017-07-07 04:05:00       0       1  0.999667\n",
      "\n",
      "P3 - top FN:\n",
      "                 timestamp  y_true  y_pred  p_attack\n",
      "67709 2017-07-07 10:36:00       1       0  0.000078\n",
      "84569 2017-07-07 12:44:00       1       0  0.000079\n",
      "67718 2017-07-07 10:36:00       1       0  0.000081\n",
      "60689 2017-07-07 10:15:00       1       0  0.000082\n",
      "66855 2017-07-07 10:34:00       1       0  0.000083\n",
      "66698 2017-07-07 10:32:00       1       0  0.000083\n",
      "67512 2017-07-07 10:35:00       1       0  0.000084\n",
      "71278 2017-07-07 11:01:00       1       0  0.000085\n",
      "68494 2017-07-07 10:39:00       1       0  0.000085\n",
      "63211 2017-07-07 10:23:00       1       0  0.000085\n"
     ]
    }
   ],
   "source": [
    "def top_cases(df, kind=\"FP\", k=20):\n",
    "    # FP: y_true=0 y_pred=1 -> alta p_attack\n",
    "    # FN: y_true=1 y_pred=0 -> baja p_attack\n",
    "    if kind == \"FP\":\n",
    "        sub = df[df[\"FP\"] == 1].sort_values(\"p_attack\", ascending=False).head(k)\n",
    "    elif kind == \"FN\":\n",
    "        sub = df[df[\"FN\"] == 1].sort_values(\"p_attack\", ascending=True).head(k)\n",
    "    else:\n",
    "        raise ValueError(\"kind debe ser FP o FN\")\n",
    "    cols = [\"timestamp\",\"y_true\",\"y_pred\",\"p_attack\"]\n",
    "    return sub[cols]\n",
    "\n",
    "print(\"P3 - top FP:\\n\", top_cases(p3t, \"FP\", 10))\n",
    "print(\"\\nP3 - top FN:\\n\", top_cases(p3t, \"FN\", 10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
