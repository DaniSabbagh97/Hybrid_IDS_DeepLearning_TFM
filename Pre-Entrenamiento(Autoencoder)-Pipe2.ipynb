{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e56a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: (2830539, 73) | ts_df: (2830539, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../Limpieza_Completada/cicids2017_CleanBinary.parquet\")\n",
    "\n",
    "ts_df = pd.read_parquet(\"../Timestamp_Datetime_Terminado/Timestamp_Tipo_Datetime.parquet\")\n",
    "\n",
    "print(\"df:\", df.shape, \"| ts_df:\", ts_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86cc67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp -> nulos: 0 | dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Unión\n",
    "df[\"Timestamp\"] = ts_df[\"Timestamp\"].values\n",
    "\n",
    "print(\"Timestamp -> nulos:\", df[\"Timestamp\"].isna().sum(), \"| dtype:\", df[\"Timestamp\"].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar\n",
    "df = df.sort_values(\"Timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f069508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_df: (2830539, 71) | y_raw: (2830539,)\n",
      "¿Attack en X_df?: False\n"
     ]
    }
   ],
   "source": [
    "#X e Y\n",
    "y_raw = df[\"Label\"].copy()  # o df[\"Attack\"] si lo guardas, pero NO se usa en AE\n",
    "\n",
    "X_df = df.select_dtypes(include=[np.number]).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb603d3",
   "metadata": {},
   "source": [
    "Split temporal (70 / 15 / 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63abeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981377, 71) (424581, 71) (424581, 71)\n"
     ]
    }
   ],
   "source": [
    "# Split temporal por índice\n",
    "n = len(X_df)\n",
    "i_train = int(n * 0.70)\n",
    "i_val   = int(n * 0.85)\n",
    "\n",
    "X_train_df = X_df.iloc[:i_train]\n",
    "X_val_df   = X_df.iloc[i_train:i_val]\n",
    "X_test_df  = X_df.iloc[i_val:]\n",
    "\n",
    "print(X_train_df.shape, X_val_df.shape, X_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300a700",
   "metadata": {},
   "source": [
    "Escalado + PCA (fit SOLO en train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0e28b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componentes PCA: 26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train_df)\n",
    "X_val_s   = scaler.transform(X_val_df)\n",
    "X_test_s  = scaler.transform(X_test_df)\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_s)\n",
    "X_val_pca   = pca.transform(X_val_s)\n",
    "X_test_pca  = pca.transform(X_test_s)\n",
    "\n",
    "print(\"Componentes PCA:\", X_train_pca.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7fc656",
   "metadata": {},
   "source": [
    "Ventanas Temporales(Solo Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e615832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "WINDOW_SIZE = 20\n",
    "STRIDE = 5\n",
    "\n",
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X, window_size, stride):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.indices = list(range(0, len(X) - window_size + 1, stride))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.indices[idx]\n",
    "        window = self.X[i:i+self.window_size]\n",
    "        return window, window  #input = target (autoencoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ccc0916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº ventanas train: 396272\n"
     ]
    }
   ],
   "source": [
    "train_dataset = WindowDataset(X_train_pca, WINDOW_SIZE, STRIDE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "print(\"Nº ventanas train:\", len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb7f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventanas val: 84913\n"
     ]
    }
   ],
   "source": [
    "#Val windows sin shuffle\n",
    "val_dataset = WindowDataset(X_val_pca, WINDOW_SIZE, STRIDE)\n",
    "val_loader  = DataLoader(val_dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "print(\"Ventanas val:\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0db8e",
   "metadata": {},
   "source": [
    "Autoencoder GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo listo en: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class GRUAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.GRU(hidden_dim, input_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D)\n",
    "        _, h = self.encoder(x)  # h: (1, B, H)\n",
    "\n",
    "        # Repetimos el estado oculto para reconstruir T pasos\n",
    "        T = x.size(1)\n",
    "        h_rep = h.repeat(T, 1, 1).permute(1, 0, 2)  # (B, T, H)\n",
    "\n",
    "        out, _ = self.decoder(h_rep)  # (B, T, D)\n",
    "        return out\n",
    "\n",
    "input_dim = X_train_pca.shape[1]\n",
    "hidden_dim = 64\n",
    "\n",
    "model = GRUAutoencoder(input_dim, hidden_dim).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"Modelo listo en:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | train=2.297568 | val=0.856266\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 2/20 | train=2.267718 | val=0.823064\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 3/20 | train=2.242814 | val=0.812399\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 4/20 | train=2.230907 | val=0.805524\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 5/20 | train=2.223228 | val=0.801729\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 6/20 | train=2.218001 | val=0.799302\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 7/20 | train=2.213951 | val=0.797667\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 8/20 | train=2.210061 | val=0.796529\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 9/20 | train=2.207198 | val=0.794897\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 10/20 | train=2.204052 | val=0.793769\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 11/20 | train=2.200531 | val=0.792445\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 12/20 | train=2.199550 | val=0.791996\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 13/20 | train=2.197381 | val=0.791198\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 14/20 | train=2.196023 | val=0.790762\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 15/20 | train=2.193235 | val=0.790261\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 16/20 | train=2.192709 | val=0.789243\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 17/20 | train=2.191040 | val=0.789274\n",
      "  · No mejora (patience 1/3)\n",
      "Epoch 18/20 | train=2.189611 | val=0.788261\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 19/20 | train=2.188323 | val=0.787933\n",
      "  ✓ Nuevo mejor modelo\n",
      "Epoch 20/20 | train=2.184739 | val=0.787480\n",
      "  ✓ Nuevo mejor modelo\n",
      "Guardado: gru_autoencoder_pca_trainonly_best.pt | best_val: 0.7874803036810404\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "EPOCHS = 20    \n",
    "PATIENCE = 3 \n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "pat = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ---- TRAIN ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device) \n",
    "        yb = yb.to(device)\n",
    "\n",
    "        noise = torch.randn_like(xb) * 0.05 #Ruido gaussiano suave\n",
    "        xb_noisy = xb + noise\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(xb_noisy)\n",
    "        loss = criterion(recon, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # ---- VAL ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            #Sin ruido en Val\n",
    "            recon = model(xb)\n",
    "            loss = criterion(recon, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | train={train_loss:.6f} | val={val_loss:.6f}\")\n",
    "\n",
    "    # ---- CHECKPOINT ----\n",
    "    if val_loss < best_val - 1e-5:\n",
    "        best_val = val_loss\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        pat = 0\n",
    "        print(\"  ✓ Nuevo mejor modelo\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        print(f\"  · No mejora (patience {pat}/{PATIENCE})\")\n",
    "\n",
    "    # ---- EARLY STOPPING ----\n",
    "    if pat >= PATIENCE:\n",
    "        print(\"Early stopping activado.\")\n",
    "        break\n",
    "\n",
    "# Cargar mejor modelo y guardar\n",
    "model.load_state_dict(best_state)\n",
    "torch.save(model.state_dict(), \"gru_autoencoder_pca_trainonly_best.pt\")\n",
    "print(\"Guardado: gru_autoencoder_pca_trainonly_best.pt | best_val:\", best_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45c824",
   "metadata": {},
   "source": [
    "Guardado Scaler y PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8899253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado scaler_trainonly.joblib y pca_trainonly.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, \"scaler_trainonly.joblib\")\n",
    "joblib.dump(pca, \"pca_trainonly.joblib\")\n",
    "\n",
    "print(\"Guardado scaler_trainonly.joblib y pca_trainonly.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac70951",
   "metadata": {},
   "source": [
    "Cargar Modelo para evitar tiempo en ejecutar Gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde gru_autoencoder_pca_trainonly_best.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = GRUAutoencoder(input_dim=X_train_pca.shape[1], hidden_dim=64).to(device)\n",
    "model.load_state_dict(torch.load(\"gru_autoencoder_pca_trainonly_best.pt\", map_location=device))\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
