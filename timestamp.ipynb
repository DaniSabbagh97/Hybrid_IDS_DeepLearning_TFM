{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63b10a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dani\\AppData\\Local\\Temp\\ipykernel_20196\\2608952604.py:8: DtypeWarning: Columns (0,1,3,6,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df6 = pd.read_csv(\"../Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\", encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"../Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "df2 = pd.read_csv(\"../Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "df3 = pd.read_csv(\"../Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "df4 = pd.read_csv(\"../Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "df5 = pd.read_csv(\"../Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "df6 = pd.read_csv(\"../Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\", encoding='latin1')\n",
    "df7 = pd.read_csv(\"../Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "df8 = pd.read_csv(\"../Wednesday-workingHours.pcap_ISCX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "663a6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df1, df2, df3, df4, df5, df6, df7, df8]:\n",
    "    df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "86101ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1.shape: (225745, 85)\n",
      "df2.shape: (286467, 85)\n",
      "df3.shape: (191033, 85)\n",
      "df4.shape: (529918, 85)\n",
      "df5.shape: (288602, 85)\n",
      "df6.shape: (458968, 85)\n",
      "df7.shape: (445909, 85)\n",
      "df8.shape: (692703, 85)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    df = eval(f'df{i}')\n",
    "    print(f'df{i}.shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b134b2e",
   "metadata": {},
   "source": [
    "OPERACIONES SIN CONCATENAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "249a5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e0a79c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7/7/2017 1:00', '7/7/2017 1:01', '7/7/2017 1:02', '7/7/2017 1:03',\n",
       "       '7/7/2017 1:04', '7/7/2017 1:05', '7/7/2017 1:06', '7/7/2017 1:07',\n",
       "       '7/7/2017 1:08', '7/7/2017 1:09', '7/7/2017 1:10', '7/7/2017 1:11',\n",
       "       '7/7/2017 1:12', '7/7/2017 1:13', '7/7/2017 1:14', '7/7/2017 1:15',\n",
       "       '7/7/2017 1:16', '7/7/2017 1:17', '7/7/2017 1:18', '7/7/2017 1:19',\n",
       "       '7/7/2017 1:20', '7/7/2017 1:21', '7/7/2017 1:22', '7/7/2017 1:23',\n",
       "       '7/7/2017 1:24', '7/7/2017 1:25', '7/7/2017 1:26', '7/7/2017 1:27',\n",
       "       '7/7/2017 1:28', '7/7/2017 1:29', '7/7/2017 1:30', '7/7/2017 1:31',\n",
       "       '7/7/2017 1:32', '7/7/2017 1:33', '7/7/2017 1:34', '7/7/2017 1:35',\n",
       "       '7/7/2017 1:36', '7/7/2017 1:37', '7/7/2017 1:38', '7/7/2017 1:39',\n",
       "       '7/7/2017 1:40', '7/7/2017 1:41', '7/7/2017 1:42', '7/7/2017 1:43',\n",
       "       '7/7/2017 1:44', '7/7/2017 1:45', '7/7/2017 1:46', '7/7/2017 1:47',\n",
       "       '7/7/2017 1:48', '7/7/2017 1:49', '7/7/2017 1:50', '7/7/2017 1:51',\n",
       "       '7/7/2017 1:52', '7/7/2017 1:53', '7/7/2017 1:54', '7/7/2017 1:55',\n",
       "       '7/7/2017 1:56', '7/7/2017 1:57', '7/7/2017 1:58', '7/7/2017 1:59',\n",
       "       '7/7/2017 2:00', '7/7/2017 2:01', '7/7/2017 2:02', '7/7/2017 2:03',\n",
       "       '7/7/2017 2:04', '7/7/2017 2:05', '7/7/2017 2:06', '7/7/2017 2:07',\n",
       "       '7/7/2017 2:08', '7/7/2017 2:09', '7/7/2017 2:10', '7/7/2017 2:11',\n",
       "       '7/7/2017 2:12', '7/7/2017 2:13', '7/7/2017 2:14', '7/7/2017 2:15',\n",
       "       '7/7/2017 2:16', '7/7/2017 2:17', '7/7/2017 2:18', '7/7/2017 2:19',\n",
       "       '7/7/2017 2:20', '7/7/2017 2:21', '7/7/2017 2:22', '7/7/2017 2:23',\n",
       "       '7/7/2017 2:24', '7/7/2017 2:25', '7/7/2017 2:26', '7/7/2017 2:27',\n",
       "       '7/7/2017 2:28', '7/7/2017 2:29', '7/7/2017 2:30', '7/7/2017 2:31',\n",
       "       '7/7/2017 2:32', '7/7/2017 2:33', '7/7/2017 2:34', '7/7/2017 2:35',\n",
       "       '7/7/2017 2:36', '7/7/2017 2:37', '7/7/2017 2:38', '7/7/2017 2:39',\n",
       "       '7/7/2017 2:40', '7/7/2017 2:41', '7/7/2017 2:42', '7/7/2017 2:43',\n",
       "       '7/7/2017 2:44', '7/7/2017 2:45', '7/7/2017 2:46', '7/7/2017 2:47',\n",
       "       '7/7/2017 2:48', '7/7/2017 2:49', '7/7/2017 2:50', '7/7/2017 2:51',\n",
       "       '7/7/2017 2:52', '7/7/2017 2:53', '7/7/2017 2:54', '7/7/2017 2:55',\n",
       "       '7/7/2017 2:56', '7/7/2017 2:57', '7/7/2017 2:58', '7/7/2017 2:59',\n",
       "       '7/7/2017 3:00', '7/7/2017 3:01', '7/7/2017 3:02', '7/7/2017 3:03',\n",
       "       '7/7/2017 3:04', '7/7/2017 3:05', '7/7/2017 3:06', '7/7/2017 3:07',\n",
       "       '7/7/2017 3:08', '7/7/2017 3:09', '7/7/2017 3:10', '7/7/2017 3:11',\n",
       "       '7/7/2017 3:12', '7/7/2017 3:13', '7/7/2017 3:14', '7/7/2017 3:15',\n",
       "       '7/7/2017 3:16', '7/7/2017 3:17', '7/7/2017 3:18', '7/7/2017 3:19',\n",
       "       '7/7/2017 3:20', '7/7/2017 3:21', '7/7/2017 3:22', '7/7/2017 3:23',\n",
       "       '7/7/2017 3:24', '7/7/2017 3:25', '7/7/2017 3:26', '7/7/2017 3:27',\n",
       "       '7/7/2017 3:28', '7/7/2017 3:29'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Timestamp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452faccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dani\\AppData\\Local\\Temp\\ipykernel_20196\\732503039.py:59: DtypeWarning: Columns (0,1,3,6,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, encoding=\"latin1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          df    rows        best_format  NaT_count      NaT_%  \\\n",
      "0            df1_friday_ddos  225745     %m/%d/%Y %H:%M          0   0.000000   \n",
      "1        df2_friday_portscan  286467     %m/%d/%Y %H:%M          0   0.000000   \n",
      "2         df3_friday_morning  191033     %m/%d/%Y %H:%M          0   0.000000   \n",
      "3                 df4_monday  529918  %m/%d/%Y %H:%M:%S          0   0.000000   \n",
      "4  df5_thursday_infiltration  288602     %m/%d/%Y %H:%M          0   0.000000   \n",
      "5    df6_thursday_webattacks  458968     %m/%d/%Y %H:%M     288602  62.880637   \n",
      "6                df7_tuesday  445909     %m/%d/%Y %H:%M          0   0.000000   \n",
      "7              df8_wednesday  692703     %m/%d/%Y %H:%M          0   0.000000   \n",
      "\n",
      "               min_dt              max_dt  unique_days  \n",
      "0 2017-07-07 03:30:00 2017-07-07 05:02:00            1  \n",
      "1 2017-07-07 01:00:00 2017-07-07 03:29:00            1  \n",
      "2 2017-07-07 08:59:00 2017-07-07 12:59:00            1  \n",
      "3 2017-03-07 01:00:01 2017-03-07 12:59:58            1  \n",
      "4 2017-06-07 01:00:00 2017-06-07 05:04:00            1  \n",
      "5 2017-06-07 08:59:00 2017-06-07 12:59:00            1  \n",
      "6 2017-04-07 01:00:00 2017-04-07 12:59:00            1  \n",
      "7 2017-05-07 01:00:00 2017-05-07 12:59:00            1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Lista de archivos (puedes ajustar paths)\n",
    "files = {\n",
    "    \"df1_friday_ddos\": \"../Friday-WorkingHours-Afternoon-DDoS.pcap_ISCX.csv\",\n",
    "    \"df2_friday_portscan\": \"../Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "    \"df3_friday_morning\": \"../Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "    \"df4_monday\": \"../Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"df5_thursday_infiltration\": \"../Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
    "    \"df6_thursday_webattacks\": \"../Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "    \"df7_tuesday\": \"../Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"df8_wednesday\": \"../Wednesday-workingHours.pcap_ISCX.csv\",\n",
    "}\n",
    "\n",
    "# 2) Formatos candidatos (los más comunes en CICIDS2017)\n",
    "CANDIDATE_FORMATS = [\n",
    "    \"%m/%d/%Y %H:%M\",      # 7/7/2017 3:30\n",
    "    \"%m/%d/%Y %H:%M:%S\",   # 7/7/2017 3:30:05\n",
    "    \"%d/%m/%Y %H:%M\",      # 7/7/2017 3:30 (interpretación DMY)\n",
    "    \"%d/%m/%Y %H:%M:%S\",   # 7/7/2017 3:30:05 (DMY)\n",
    "    \"%Y-%m-%d %H:%M:%S\",   # 2017-07-07 03:30:05\n",
    "    \"%Y-%m-%d %H:%M\",      # 2017-07-07 03:30\n",
    "]\n",
    "\n",
    "def parse_timestamp_best(series: pd.Series):\n",
    "    \"\"\"\n",
    "    Intenta varios formatos y se queda con el que produce menos NaT.\n",
    "    Devuelve (dt, best_format, nat_count).\n",
    "    \"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "\n",
    "    best = None\n",
    "    best_fmt = None\n",
    "    best_nat = None\n",
    "\n",
    "    for fmt in CANDIDATE_FORMATS:\n",
    "        dt = pd.to_datetime(s, format=fmt, errors=\"coerce\")\n",
    "        nat = dt.isna().sum()\n",
    "        if best_nat is None or nat < best_nat:\n",
    "            best, best_fmt, best_nat = dt, fmt, nat\n",
    "            if best_nat == 0:\n",
    "                break\n",
    "\n",
    "    # Fallback final: parser flexible (por si hay cosas raras)\n",
    "    if best_nat is None:\n",
    "        best = pd.to_datetime(s, errors=\"coerce\")\n",
    "        best_fmt = \"infer\"\n",
    "        best_nat = best.isna().sum()\n",
    "\n",
    "    return best, best_fmt, best_nat\n",
    "\n",
    "\n",
    "report_rows = []\n",
    "dfs = {}\n",
    "\n",
    "for name, path in files.items():\n",
    "    # OJO con encoding en el que ya sabes que falla\n",
    "    if \"webattacks\" in name:\n",
    "        df = pd.read_csv(path, encoding=\"latin1\")\n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "    # Limpia nombres de columnas por si hay espacios tipo ' Timestamp'\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    if \"Timestamp\" not in df.columns:\n",
    "        raise ValueError(f\"{name}: no encuentro columna 'Timestamp'. Columnas: {df.columns.tolist()[:10]} ...\")\n",
    "\n",
    "    df[\"dt\"], best_fmt, nat_count = parse_timestamp_best(df[\"Timestamp\"])\n",
    "\n",
    "    report_rows.append({\n",
    "        \"df\": name,\n",
    "        \"rows\": len(df),\n",
    "        \"best_format\": best_fmt,\n",
    "        \"NaT_count\": int(nat_count),\n",
    "        \"NaT_%\": float(nat_count / len(df) * 100),\n",
    "        \"min_dt\": df[\"dt\"].min(),\n",
    "        \"max_dt\": df[\"dt\"].max(),\n",
    "        \"unique_days\": int(df[\"dt\"].dt.date.nunique(dropna=True)),\n",
    "    })\n",
    "\n",
    "    dfs[name] = df\n",
    "\n",
    "report = pd.DataFrame(report_rows).sort_values(\"df\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "12097525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaT: 288602\n",
      "2017-06-07 08:59:00 2017-06-07 12:59:00\n"
     ]
    }
   ],
   "source": [
    "s = df6[\"Timestamp\"].astype(str).str.strip()\n",
    "\n",
    "dt1 = pd.to_datetime(s, format=\"%m/%d/%Y %H:%M\", errors=\"coerce\")\n",
    "dt2 = pd.to_datetime(s, format=\"%m/%d/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "df6[\"dt\"] = dt1.fillna(dt2)\n",
    "\n",
    "print(\"NaT:\", df6[\"dt\"].isna().sum())\n",
    "print(df6[\"dt\"].min(), df6[\"dt\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81636d4a",
   "metadata": {},
   "source": [
    "BORRAR NAN DF 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "93a7e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.dropna(subset=[\"Timestamp\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b59b56cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170366, 86)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6[\"Timestamp\"].isna().sum()\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e1c0bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6/7/2017 8:59', '6/7/2017 9:00', '6/7/2017 9:01', '6/7/2017 9:02',\n",
       "       '6/7/2017 9:03', '6/7/2017 9:04', '6/7/2017 9:05', '6/7/2017 9:06',\n",
       "       '6/7/2017 9:07', '6/7/2017 9:08', '6/7/2017 9:09', '6/7/2017 9:10',\n",
       "       '6/7/2017 9:11', '6/7/2017 9:12', '6/7/2017 9:13', '6/7/2017 9:14',\n",
       "       '6/7/2017 9:15', '6/7/2017 9:16', '6/7/2017 9:17', '6/7/2017 9:18',\n",
       "       '6/7/2017 9:19', '6/7/2017 9:20', '6/7/2017 9:21', '6/7/2017 9:22',\n",
       "       '6/7/2017 9:23', '6/7/2017 9:24', '6/7/2017 9:25', '6/7/2017 9:26',\n",
       "       '6/7/2017 9:27', '6/7/2017 9:28', '6/7/2017 9:29', '6/7/2017 9:30',\n",
       "       '6/7/2017 9:31', '6/7/2017 9:32', '6/7/2017 9:33', '6/7/2017 9:34',\n",
       "       '6/7/2017 9:35', '6/7/2017 9:36', '6/7/2017 9:37', '6/7/2017 9:38',\n",
       "       '6/7/2017 9:39', '6/7/2017 9:40', '6/7/2017 9:41', '6/7/2017 9:42',\n",
       "       '6/7/2017 9:43', '6/7/2017 9:44', '6/7/2017 9:45', '6/7/2017 9:46',\n",
       "       '6/7/2017 9:47', '6/7/2017 9:48', '6/7/2017 9:49', '6/7/2017 9:50',\n",
       "       '6/7/2017 9:51', '6/7/2017 9:52', '6/7/2017 9:53', '6/7/2017 9:54',\n",
       "       '6/7/2017 9:55', '6/7/2017 9:56', '6/7/2017 9:57', '6/7/2017 9:58',\n",
       "       '6/7/2017 9:59', '6/7/2017 10:00', '6/7/2017 10:01',\n",
       "       '6/7/2017 10:02', '6/7/2017 10:03', '6/7/2017 10:04',\n",
       "       '6/7/2017 10:05', '6/7/2017 10:06', '6/7/2017 10:07',\n",
       "       '6/7/2017 10:08', '6/7/2017 10:09', '6/7/2017 10:10',\n",
       "       '6/7/2017 10:11', '6/7/2017 10:12', '6/7/2017 10:13',\n",
       "       '6/7/2017 10:14', '6/7/2017 10:15', '6/7/2017 10:16',\n",
       "       '6/7/2017 10:17', '6/7/2017 10:18', '6/7/2017 10:19',\n",
       "       '6/7/2017 10:20', '6/7/2017 10:21', '6/7/2017 10:22',\n",
       "       '6/7/2017 10:23', '6/7/2017 10:24', '6/7/2017 10:25',\n",
       "       '6/7/2017 10:26', '6/7/2017 10:27', '6/7/2017 10:28',\n",
       "       '6/7/2017 10:29', '6/7/2017 10:30', '6/7/2017 10:31',\n",
       "       '6/7/2017 10:32', '6/7/2017 10:33', '6/7/2017 10:34',\n",
       "       '6/7/2017 10:35', '6/7/2017 10:36', '6/7/2017 10:37',\n",
       "       '6/7/2017 10:38', '6/7/2017 10:39', '6/7/2017 10:40',\n",
       "       '6/7/2017 10:41', '6/7/2017 10:42', '6/7/2017 10:43',\n",
       "       '6/7/2017 10:44', '6/7/2017 10:45', '6/7/2017 10:46',\n",
       "       '6/7/2017 10:47', '6/7/2017 10:48', '6/7/2017 10:49',\n",
       "       '6/7/2017 10:50', '6/7/2017 10:51', '6/7/2017 10:52',\n",
       "       '6/7/2017 10:53', '6/7/2017 10:54', '6/7/2017 10:55',\n",
       "       '6/7/2017 10:56', '6/7/2017 10:57', '6/7/2017 10:58',\n",
       "       '6/7/2017 10:59', '6/7/2017 11:00', '6/7/2017 11:01',\n",
       "       '6/7/2017 11:02', '6/7/2017 11:03', '6/7/2017 11:04',\n",
       "       '6/7/2017 11:05', '6/7/2017 11:06', '6/7/2017 11:07',\n",
       "       '6/7/2017 11:08', '6/7/2017 11:09', '6/7/2017 11:10',\n",
       "       '6/7/2017 11:11', '6/7/2017 11:12', '6/7/2017 11:13',\n",
       "       '6/7/2017 11:14', '6/7/2017 11:15', '6/7/2017 11:16',\n",
       "       '6/7/2017 11:17', '6/7/2017 11:18', '6/7/2017 11:19',\n",
       "       '6/7/2017 11:20', '6/7/2017 11:21', '6/7/2017 11:22',\n",
       "       '6/7/2017 11:23', '6/7/2017 11:24', '6/7/2017 11:25',\n",
       "       '6/7/2017 11:26', '6/7/2017 11:27', '6/7/2017 11:28',\n",
       "       '6/7/2017 11:29', '6/7/2017 11:30', '6/7/2017 11:31',\n",
       "       '6/7/2017 11:32', '6/7/2017 11:33', '6/7/2017 11:34',\n",
       "       '6/7/2017 11:35', '6/7/2017 11:36', '6/7/2017 11:37',\n",
       "       '6/7/2017 11:38', '6/7/2017 11:39', '6/7/2017 11:40',\n",
       "       '6/7/2017 11:41', '6/7/2017 11:42', '6/7/2017 11:43',\n",
       "       '6/7/2017 11:44', '6/7/2017 11:45', '6/7/2017 11:46',\n",
       "       '6/7/2017 11:47', '6/7/2017 11:48', '6/7/2017 11:49',\n",
       "       '6/7/2017 11:50', '6/7/2017 11:51', '6/7/2017 11:52',\n",
       "       '6/7/2017 11:53', '6/7/2017 11:54', '6/7/2017 11:55',\n",
       "       '6/7/2017 11:56', '6/7/2017 11:57', '6/7/2017 11:58',\n",
       "       '6/7/2017 11:59', '6/7/2017 12:00', '6/7/2017 12:01',\n",
       "       '6/7/2017 12:02', '6/7/2017 12:03', '6/7/2017 12:04',\n",
       "       '6/7/2017 12:05', '6/7/2017 12:06', '6/7/2017 12:07',\n",
       "       '6/7/2017 12:08', '6/7/2017 12:09', '6/7/2017 12:10',\n",
       "       '6/7/2017 12:11', '6/7/2017 12:12', '6/7/2017 12:13',\n",
       "       '6/7/2017 12:14', '6/7/2017 12:15', '6/7/2017 12:16',\n",
       "       '6/7/2017 12:17', '6/7/2017 12:18', '6/7/2017 12:19',\n",
       "       '6/7/2017 12:20', '6/7/2017 12:21', '6/7/2017 12:22',\n",
       "       '6/7/2017 12:23', '6/7/2017 12:24', '6/7/2017 12:25',\n",
       "       '6/7/2017 12:26', '6/7/2017 12:27', '6/7/2017 12:28',\n",
       "       '6/7/2017 12:29', '6/7/2017 12:30', '6/7/2017 12:31',\n",
       "       '6/7/2017 12:32', '6/7/2017 12:33', '6/7/2017 12:34',\n",
       "       '6/7/2017 12:35', '6/7/2017 12:36', '6/7/2017 12:37',\n",
       "       '6/7/2017 12:38', '6/7/2017 12:39', '6/7/2017 12:40',\n",
       "       '6/7/2017 12:41', '6/7/2017 12:42', '6/7/2017 12:43',\n",
       "       '6/7/2017 12:44', '6/7/2017 12:45', '6/7/2017 12:46',\n",
       "       '6/7/2017 12:47', '6/7/2017 12:48', '6/7/2017 12:49',\n",
       "       '6/7/2017 12:50', '6/7/2017 12:51', '6/7/2017 12:52',\n",
       "       '6/7/2017 12:53', '6/7/2017 12:54', '6/7/2017 12:55',\n",
       "       '6/7/2017 12:56', '6/7/2017 12:57', '6/7/2017 12:58',\n",
       "       '6/7/2017 12:59'], dtype=object)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['Timestamp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d66578",
   "metadata": {},
   "source": [
    "COMIENZA LIMPIEZA TIMESTAMP DF A DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71018f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp_standard(df):\n",
    "    df[\"dt\"] = pd.to_datetime(\n",
    "        df[\"Timestamp\"],\n",
    "        format=\"%d/%m/%Y %H:%M\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8261c99",
   "metadata": {},
   "source": [
    "Operar con df4 que parece que da problemas con la conversión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3e49d84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/07/2017 08:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/07/2017 08:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/07/2017 08:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/07/2017 08:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/07/2017 08:56:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp\n",
       "0  03/07/2017 08:55:58\n",
       "1  03/07/2017 08:55:58\n",
       "2  03/07/2017 08:55:58\n",
       "3  03/07/2017 08:55:58\n",
       "4  03/07/2017 08:56:22"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[[\"Timestamp\"]].head()   # si esto da KeyError, NO existe \"Timestamp\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "27d96e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df4 NaT: 0\n",
      "2017-03-07 01:00:01 2017-03-07 12:59:58\n"
     ]
    }
   ],
   "source": [
    "df4[\"dt\"] = pd.to_datetime(\n",
    "    df4[\"Timestamp\"],\n",
    "    format=\"%m/%d/%Y %H:%M:%S\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "print(\"df4 NaT:\", df4[\"dt\"].isna().sum())\n",
    "print(df4[\"dt\"].min(), df4[\"dt\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a395afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = convert_timestamp_standard(df1)\n",
    "df2 = convert_timestamp_standard(df2)\n",
    "df3 = convert_timestamp_standard(df3)\n",
    "#df4 = convert_timestamp_standard(df4)\n",
    "df5 = convert_timestamp_standard(df5)\n",
    "df6 = convert_timestamp_standard(df6)\n",
    "df7 = convert_timestamp_standard(df7)\n",
    "df8 = convert_timestamp_standard(df8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cc7b0128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 NaT: 0\n",
      "df2 NaT: 0\n",
      "df3 NaT: 0\n",
      "df4 NaT: 0\n",
      "df5 NaT: 0\n",
      "df7 NaT: 0\n",
      "df8 NaT: 0\n"
     ]
    }
   ],
   "source": [
    "for name, df in zip(\n",
    "    [\"df1\",\"df2\",\"df3\",\"df4\",\"df5\",\"df7\",\"df8\"],\n",
    "    [df1,df2,df3,df4,df5,df7,df8]\n",
    "):\n",
    "    print(name, \"NaT:\", df[\"dt\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f8a9c13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df1['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9bee621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df2['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "68aff670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df3['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "583c9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df4['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f2bb39a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df5['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b0cc6b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df6['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "191ef774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df7['dt']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ea734c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df8['dt']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "51c7698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimension:\n",
      "Number of rows: 2830743\n",
      "Number of columns: 86\n",
      "Total cells: 243443898\n"
     ]
    }
   ],
   "source": [
    "data_list = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "rows, cols = df.shape\n",
    "print('New dimension:')\n",
    "print(f'Number of rows: {rows}')\n",
    "print(f'Number of columns: {cols}')\n",
    "print(f'Total cells: {rows * cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b1838bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Timestamp'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7261fb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTimestamp = df[['Timestamp']]\n",
    "\n",
    "type(dfTimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9a18eb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830743, 1)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTimestamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b488c7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2802778"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups = dfTimestamp[dfTimestamp.duplicated()]\n",
    "len(dups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
