{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2960e2f",
   "metadata": {},
   "source": [
    "### Pipeline 2 — PCA → GRU Encoder (pre-entreno) → TCN\n",
    "\n",
    "- El pre-entreno guardó:\n",
    "  - scaler_trainonly.joblib\n",
    "  - pca_trainonly.joblib\n",
    "  - gru_autoencoder_pca_trainonly_best.pt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4899902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: (2830539, 73) | ts_df: (2830539, 1)\n",
      "Timestamp -> nulos: 0 | dtype: datetime64[ns]\n",
      "0   2017-07-03 01:00:01\n",
      "1   2017-07-03 01:00:01\n",
      "2   2017-07-03 01:00:01\n",
      "Name: Timestamp, dtype: datetime64[ns]\n",
      "2830536   2017-07-07 12:59:00\n",
      "2830537   2017-07-07 12:59:00\n",
      "2830538   2017-07-07 12:59:00\n",
      "Name: Timestamp, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../Limpieza_Completada/cicids2017_CleanBinary.parquet\")\n",
    "ts_df = pd.read_parquet(\"../Timestamp_Datetime_Terminado/Timestamp_Tipo_Datetime.parquet\")\n",
    "\n",
    "#Unión\n",
    "df[\"Timestamp\"] = ts_df[\"Timestamp\"].values\n",
    "#Ordenar \n",
    "df = df.sort_values(\"Timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c046223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_df: (2830539, 71) | y: (2830539,)\n",
      "Attack bincount: [2272894  557645]\n"
     ]
    }
   ],
   "source": [
    "#X Y\n",
    "y = df[\"Attack\"].astype(np.int64).values\n",
    "X_df = df.select_dtypes(include=[np.number]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65805c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1981377, 71) (424581, 71) (424581, 71)\n",
      "y: (1981377,) (424581,) (424581,)\n",
      "train bincount: [1714580  266797]  | val: [264157 160424]  | test: [294157 130424]\n"
     ]
    }
   ],
   "source": [
    "#Split temporal (70/15/15)\n",
    "n = len(df)\n",
    "i_train = int(n * 0.70)\n",
    "i_val   = int(n * 0.85)\n",
    "\n",
    "X_train_df = X_df.iloc[:i_train]\n",
    "X_val_df   = X_df.iloc[i_train:i_val]\n",
    "X_test_df  = X_df.iloc[i_val:]\n",
    "\n",
    "y_train = y[:i_train]\n",
    "y_val   = y[i_train:i_val]\n",
    "y_test  = y[i_val:]\n",
    "\n",
    "print(\"X:\", X_train_df.shape, X_val_df.shape, X_test_df.shape)\n",
    "print(\"y:\", y_train.shape, y_val.shape, y_test.shape)\n",
    "print(\"train bincount:\", np.bincount(y_train), \" | val:\", np.bincount(y_val), \" | test:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shapes: (1981377, 26) (424581, 26) (424581, 26)\n",
      "NaNs PCA: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Cargar scaler + PCA (pre-entreno) y transformar\n",
    "import joblib\n",
    "\n",
    "scaler = joblib.load(\"scaler_trainonly.joblib\")\n",
    "pca    = joblib.load(\"pca_trainonly.joblib\")\n",
    "\n",
    "X_train_pca = pca.transform(scaler.transform(X_train_df))\n",
    "X_val_pca   = pca.transform(scaler.transform(X_val_df))\n",
    "X_test_pca  = pca.transform(scaler.transform(X_test_df))\n",
    "\n",
    "print(\"PCA shapes:\", X_train_pca.shape, X_val_pca.shape, X_test_pca.shape)\n",
    "print(\"NaNs PCA:\", np.isnan(X_train_pca).sum(), np.isnan(X_val_pca).sum(), np.isnan(X_test_pca).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad59d4",
   "metadata": {},
   "source": [
    "### Ventanas temporales (secuencias)\n",
    "\n",
    "Convertimos el flujo tabular en ventanas de longitud 20.\n",
    "\n",
    "- La etiqueta de la ventana es la del último flujo de la ventana (clasificación \"a futuro\" dentro de la ventana).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows: 396272 84913 84913\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "WINDOW_SIZE = 20\n",
    "STRIDE = 5\n",
    "\n",
    "def make_window_starts(n, window_size, stride):\n",
    "    \n",
    "    return list(range(0, n - window_size + 1, stride))\n",
    "\n",
    "class SeqWindowBinaryDataset(Dataset):\n",
    "    def __init__(self, X_pca, y_bin, window_size, stride):\n",
    "        self.X = torch.tensor(X_pca, dtype=torch.float32)\n",
    "        self.y = np.asarray(y_bin, dtype=np.int64)\n",
    "        self.ws = window_size\n",
    "        self.starts = make_window_starts(len(self.y), window_size, stride)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        i = self.starts[k]\n",
    "        x_win = self.X[i:i+self.ws]              # (T, D)\n",
    "        y_win = int(self.y[i+self.ws-1])         # etiqueta del último flujo\n",
    "        return x_win, y_win\n",
    "\n",
    "train_ds = SeqWindowBinaryDataset(X_train_pca, y_train, WINDOW_SIZE, STRIDE)\n",
    "val_ds   = SeqWindowBinaryDataset(X_val_pca,   y_val,   WINDOW_SIZE, STRIDE)\n",
    "test_ds  = SeqWindowBinaryDataset(X_test_pca,  y_test,  WINDOW_SIZE, STRIDE)\n",
    "\n",
    "print(\"windows:\", len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train window bincount: [342971  53301]\n",
      "batches: 1547 332 332\n"
     ]
    }
   ],
   "source": [
    "def window_labels_last(y_flow, window_size, stride):\n",
    "    y_flow = np.asarray(y_flow, dtype=np.int64)\n",
    "    starts = make_window_starts(len(y_flow), window_size, stride)\n",
    "    return np.array([y_flow[s + window_size - 1] for s in starts], dtype=np.int64)\n",
    "\n",
    "y_train_w = window_labels_last(y_train, WINDOW_SIZE, STRIDE)\n",
    "counts_w = np.bincount(y_train_w, minlength=2)\n",
    "print(\"train window bincount:\", counts_w)\n",
    "\n",
    "class_weights = 1.0 / np.maximum(counts_w, 1)\n",
    "sample_weights = class_weights[y_train_w]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.tensor(sample_weights, dtype=torch.double),\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 256  \n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "print(\"batches:\", len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb0fe5",
   "metadata": {},
   "source": [
    "### Modelo: GRU Encoder congelado + TCN + capa final\n",
    "\n",
    "- Cargamos el encoder del autoencoder GRU pre-entrenado.\n",
    "- TCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f48410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder cargado y congelado.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "D_PCA = X_train_pca.shape[1]\n",
    "H = 64  #hidden size del encoder\n",
    "\n",
    "#encoder con la misma arquitectura que en el pre-entreno\n",
    "encoder = nn.GRU(input_size=D_PCA, hidden_size=H, batch_first=True).to(device)\n",
    "\n",
    "state = torch.load(\"gru_autoencoder_pca_trainonly_best.pt\", map_location=device)\n",
    "\n",
    "enc_state = {k.replace(\"encoder.\", \"\"): v for k, v in state.items() if k.startswith(\"encoder.\")}\n",
    "encoder.load_state_dict(enc_state, strict=True)\n",
    "encoder.eval()\n",
    "\n",
    "for p in encoder.parameters():#Congelar encoder\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c465488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCNBinaryClassifier(\n",
      "  (tcn): Sequential(\n",
      "    (0): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#TCN (causal) + clasificador\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size] if self.chomp_size > 0 else x\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(F.relu(self.chomp1(self.conv1(x))))\n",
    "        out = self.drop2(F.relu(self.chomp2(self.conv2(out))))\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return F.relu(out + res)\n",
    "\n",
    "class TCNBinaryClassifier(nn.Module):\n",
    "    def __init__(self, in_ch, channels=(64, 64, 64), kernel_size=3, dropout=0.2, n_classes=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch_in = in_ch\n",
    "        for i, ch_out in enumerate(channels):\n",
    "            dil = 2 ** i\n",
    "            layers.append(TemporalBlock(ch_in, ch_out, kernel_size, dil, dropout))\n",
    "            ch_in = ch_out\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(ch_in, n_classes)\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        # x_seq: (B, T, H)\n",
    "        x = x_seq.transpose(1, 2)  # (B, H, T)\n",
    "        y = self.tcn(x)            # (B, C, T)\n",
    "        last = y[:, :, -1]         # (B, C)\n",
    "        return self.fc(last)       # (B, 2)\n",
    "\n",
    "tcn_head = TCNBinaryClassifier(in_ch=H, channels=(64, 64, 64), kernel_size=3, dropout=0.2, n_classes=2).to(device)\n",
    "print(tcn_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba583d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights: [0.26901219 1.73098781]\n"
     ]
    }
   ],
   "source": [
    "#Loss + optimizer\n",
    "\n",
    "counts_w = np.bincount(y_train_w, minlength=2)\n",
    "w = 1.0 / np.maximum(counts_w, 1)\n",
    "w = w / w.sum() * 2\n",
    "class_weights = torch.tensor(w, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.02)\n",
    "\n",
    "optimizer = torch.optim.AdamW(tcn_head.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "print(\"class_weights:\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fe067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 | train loss=0.1338 acc=0.9122 | val loss=0.8966 acc=0.7351 | VAL AP(Attack)=0.5359\n",
      "Epoch 2/8 | train loss=0.1136 acc=0.9365 | val loss=1.0258 acc=0.6218 | VAL AP(Attack)=0.5116\n",
      "Epoch 3/8 | train loss=0.1052 acc=0.9423 | val loss=0.8210 acc=0.7544 | VAL AP(Attack)=0.6466\n",
      "Epoch 4/8 | train loss=0.0990 acc=0.9453 | val loss=0.8983 acc=0.7402 | VAL AP(Attack)=0.6087\n",
      "Epoch 5/8 | train loss=0.0939 acc=0.9478 | val loss=0.8910 acc=0.7574 | VAL AP(Attack)=0.6420\n",
      "Epoch 6/8 | train loss=0.0907 acc=0.9508 | val loss=0.8423 acc=0.7578 | VAL AP(Attack)=0.6576\n",
      "Epoch 7/8 | train loss=0.0880 acc=0.9526 | val loss=0.8183 acc=0.7689 | VAL AP(Attack)=0.6769\n",
      "Epoch 8/8 | train loss=0.0859 acc=0.9546 | val loss=0.8390 acc=0.7706 | VAL AP(Attack)=0.7008\n",
      "Best VAL AP(Attack): 0.7008067394148463\n"
     ]
    }
   ],
   "source": [
    "#Train / Eval loops \n",
    "from sklearn.metrics import average_precision_score, f1_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "def predict_proba(loader):\n",
    "    encoder.eval()\n",
    "    tcn_head.eval()\n",
    "    ys, prob_attack = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            out_seq, _ = encoder(xb)              # (B, T, H)\n",
    "            logits = tcn_head(out_seq)            # (B, 2)\n",
    "            probs = torch.softmax(logits, dim=1)  # (B, 2)\n",
    "            ys.append(yb.numpy())\n",
    "            prob_attack.append(probs[:, 1].cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    p1 = np.concatenate(prob_attack)\n",
    "    y_pred = (p1 >= 0.5).astype(np.int64)\n",
    "    return y_true, y_pred, p1\n",
    "\n",
    "def run_epoch(train=True):\n",
    "    if train:\n",
    "        tcn_head.train()\n",
    "    else:\n",
    "        tcn_head.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    loader = train_loader if train else val_loader\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            out_seq, _ = encoder(xb)\n",
    "            logits = tcn_head(out_seq)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(tcn_head.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "EPOCHS = 8\n",
    "best_val_ap = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train=True)\n",
    "    va_loss, va_acc = run_epoch(train=False)\n",
    "\n",
    "    yv, yv_pred, yv_p1 = predict_proba(val_loader)\n",
    "    val_ap = average_precision_score(yv, yv_p1)  # AP para clase Attack (positiva)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train loss={tr_loss:.4f} acc={tr_acc:.4f} | val loss={va_loss:.4f} acc={va_acc:.4f} | VAL AP(Attack)={val_ap:.4f}\")\n",
    "\n",
    "    if val_ap > best_val_ap:\n",
    "        best_val_ap = val_ap\n",
    "        best_state = {k: v.cpu().clone() for k, v in tcn_head.state_dict().items()}\n",
    "\n",
    "print(\"Best VAL AP(Attack):\", best_val_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845abc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics\n",
      "F1 macro: 0.941878005223491\n",
      "Balanced Accuracy: 0.9572873718427528\n",
      "MCC: 0.8873019356108054\n",
      "PR-AUC (Attack): 0.987859877884341\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9902    0.9355    0.9621     58826\n",
      "           1     0.8707    0.9791    0.9217     26087\n",
      "\n",
      "    accuracy                         0.9489     84913\n",
      "   macro avg     0.9304    0.9573    0.9419     84913\n",
      "weighted avg     0.9535    0.9489    0.9497     84913\n",
      "\n",
      "Confusion matrix:\n",
      " [[55032  3794]\n",
      " [  546 25541]]\n"
     ]
    }
   ],
   "source": [
    "#TEST (threshold=0.5)\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "\n",
    "tcn_head.load_state_dict(best_state)\n",
    "tcn_head.to(device)\n",
    "\n",
    "y_true, y_pred, p1 = predict_proba(test_loader)\n",
    "\n",
    "f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "mcc      = matthews_corrcoef(y_true, y_pred)\n",
    "ap_attack = average_precision_score(y_true, p1)\n",
    "\n",
    "print(\"TEST metrics\")\n",
    "print(\"F1 macro:\", f1_macro)\n",
    "print(\"Balanced Accuracy:\", bal_acc)\n",
    "print(\"MCC:\", mcc)\n",
    "print(\"PR-AUC (Attack):\", ap_attack)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def252de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Curva Precision-Recall (Attack) en TEST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_true, p1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rec, prec)\n",
    "plt.title(\"Precision-Recall (Attack) - TEST\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f55698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: tcn_binary_head_best.pt, metrics_pipeline2_binary.json\n"
     ]
    }
   ],
   "source": [
    "#Guardar artefactos (head + métricas)\n",
    "import json\n",
    "\n",
    "torch.save(tcn_head.state_dict(), \"tcn_binary_head_best.pt\")\n",
    "\n",
    "metrics = {\n",
    "    \"best_val_ap_attack\": float(best_val_ap),\n",
    "    \"test_f1_macro\": float(f1_macro),\n",
    "    \"test_balanced_accuracy\": float(bal_acc),\n",
    "    \"test_mcc\": float(mcc),\n",
    "    \"test_pr_auc_attack\": float(ap_attack),\n",
    "    \"confusion_matrix\": cm.tolist()\n",
    "}\n",
    "\n",
    "with open(\"metrics_pipeline2_binary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Guardado: tcn_binary_head_best.pt, metrics_pipeline2_binary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
