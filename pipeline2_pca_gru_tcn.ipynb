{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2960e2f",
   "metadata": {},
   "source": [
    "### Pipeline 2 — PCA → GRU Encoder (pre-entreno) → TCN\n",
    "\n",
    "- El pre-entreno guardó:\n",
    "  - scaler_trainonly.joblib\n",
    "  - pca_trainonly.joblib\n",
    "  - gru_autoencoder_pca_trainonly_best.pt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4899902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4938b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../Limpieza_Completada/cicids2017_CleanBinary.parquet\")\n",
    "ts_df = pd.read_parquet(\"../Timestamp_Datetime_Terminado/Timestamp_Tipo_Datetime.parquet\")\n",
    "\n",
    "#Unión\n",
    "df[\"Timestamp\"] = ts_df[\"Timestamp\"].values\n",
    "#Ordenar \n",
    "df = df.sort_values(\"Timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c046223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X Y\n",
    "y = df[\"Attack\"].astype(np.int64).values\n",
    "X_df = df.select_dtypes(include=[np.number]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65805c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1981377, 72) (424581, 72) (424581, 72)\n",
      "y: (1981377,) (424581,) (424581,)\n",
      "train bincount: [1714580  266797]  | val: [264157 160424]  | test: [294157 130424]\n"
     ]
    }
   ],
   "source": [
    "#Split temporal (70/15/15)\n",
    "n = len(df)\n",
    "i_train = int(n * 0.70)\n",
    "i_val   = int(n * 0.85)\n",
    "\n",
    "X_train_df = X_df.iloc[:i_train]\n",
    "X_val_df   = X_df.iloc[i_train:i_val]\n",
    "X_test_df  = X_df.iloc[i_val:]\n",
    "\n",
    "y_train = y[:i_train]\n",
    "y_val   = y[i_train:i_val]\n",
    "y_test  = y[i_val:]\n",
    "\n",
    "print(\"X:\", X_train_df.shape, X_val_df.shape, X_test_df.shape)\n",
    "print(\"y:\", y_train.shape, y_val.shape, y_test.shape)\n",
    "print(\"train bincount:\", np.bincount(y_train), \" | val:\", np.bincount(y_val), \" | test:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ea9371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dims: (1981377, 26) (424581, 26) (424581, 26)\n",
      "n_components: 26\n",
      "NaNs PCA: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_df)\n",
    "X_val_sc   = scaler.transform(X_val_df)\n",
    "X_test_sc  = scaler.transform(X_test_df)\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_sc)\n",
    "X_val_pca   = pca.transform(X_val_sc)\n",
    "X_test_pca  = pca.transform(X_test_sc)\n",
    "\n",
    "print(\"PCA dims:\", X_train_pca.shape, X_val_pca.shape, X_test_pca.shape)\n",
    "print(\"n_components:\", X_train_pca.shape[1])\n",
    "print(\"NaNs PCA:\", np.isnan(X_train_pca).sum(), np.isnan(X_val_pca).sum(), np.isnan(X_test_pca).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shapes: (1981377, 26) (424581, 26) (424581, 26)\n",
      "NaNs PCA: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Cargar scaler + PCA (pre-entreno) y transformar\n",
    "#import joblib\n",
    "\n",
    "#scaler = joblib.load(\"scaler_trainonly.joblib\")\n",
    "#pca    = joblib.load(\"pca_trainonly.joblib\")\n",
    "\n",
    "#X_train_pca = pca.transform(scaler.transform(X_train_df))\n",
    "#X_val_pca   = pca.transform(scaler.transform(X_val_df))\n",
    "#X_test_pca  = pca.transform(scaler.transform(X_test_df))\n",
    "\n",
    "#print(\"PCA shapes:\", X_train_pca.shape, X_val_pca.shape, X_test_pca.shape)\n",
    "#print(\"NaNs PCA:\", np.isnan(X_train_pca).sum(), np.isnan(X_val_pca).sum(), np.isnan(X_test_pca).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad59d4",
   "metadata": {},
   "source": [
    "### Ventanas temporales (secuencias)\n",
    "\n",
    "Convertimos el flujo tabular en ventanas de longitud 20.\n",
    "\n",
    "- La etiqueta de la ventana es la del último flujo de la ventana (clasificación \"a futuro\" dentro de la ventana).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc37bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows: 396272 84913 84913\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "WINDOW_SIZE = 20\n",
    "STRIDE = 5\n",
    "\n",
    "def make_window_starts(n, window_size, stride):\n",
    "    \n",
    "    return list(range(0, n - window_size + 1, stride))\n",
    "\n",
    "class SeqWindowBinaryDataset(Dataset):\n",
    "    def __init__(self, X_pca, y_bin, window_size, stride):\n",
    "        self.X = torch.tensor(X_pca, dtype=torch.float32)\n",
    "        self.y = np.asarray(y_bin, dtype=np.int64)\n",
    "        self.ws = window_size\n",
    "        self.starts = make_window_starts(len(self.y), window_size, stride)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        i = self.starts[k]\n",
    "        x_win = self.X[i:i+self.ws]              # (T, D)\n",
    "        y_win = int(self.y[i+self.ws-1])         # etiqueta del último flujo\n",
    "        return x_win, y_win\n",
    "\n",
    "train_ds = SeqWindowBinaryDataset(X_train_pca, y_train, WINDOW_SIZE, STRIDE)\n",
    "val_ds   = SeqWindowBinaryDataset(X_val_pca,   y_val,   WINDOW_SIZE, STRIDE)\n",
    "test_ds  = SeqWindowBinaryDataset(X_test_pca,  y_test,  WINDOW_SIZE, STRIDE)\n",
    "\n",
    "print(\"windows:\", len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab8b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train window bincount: [342971  53301]\n",
      "batches: 1547 332 332\n"
     ]
    }
   ],
   "source": [
    "def window_labels_last(y_flow, window_size, stride):\n",
    "    y_flow = np.asarray(y_flow, dtype=np.int64)\n",
    "    starts = make_window_starts(len(y_flow), window_size, stride)\n",
    "    return np.array([y_flow[s + window_size - 1] for s in starts], dtype=np.int64)\n",
    "\n",
    "y_train_w = window_labels_last(y_train, WINDOW_SIZE, STRIDE)\n",
    "counts_w = np.bincount(y_train_w, minlength=2)\n",
    "print(\"train window bincount:\", counts_w)\n",
    "\n",
    "class_weights = 1.0 / np.maximum(counts_w, 1)\n",
    "sample_weights = class_weights[y_train_w]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.tensor(sample_weights, dtype=torch.double),\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 256  \n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "print(\"batches:\", len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb0fe5",
   "metadata": {},
   "source": [
    "### Modelo: GRU Encoder congelado + TCN + capa final\n",
    "\n",
    "- Cargamos el encoder del autoencoder GRU pre-entrenado.\n",
    "- TCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f48410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "D_PCA = X_train_pca.shape[1]\n",
    "H = 64  #hidden size del encoder\n",
    "\n",
    "#encoder con la misma arquitectura que en el pre-entreno\n",
    "encoder = nn.GRU(input_size=D_PCA, hidden_size=H, batch_first=True).to(device)\n",
    "\n",
    "state = torch.load(\"gru_autoencoder_pca_trainonly_best.pt\", map_location=device)\n",
    "\n",
    "enc_state = {k.replace(\"encoder.\", \"\"): v for k, v in state.items() if k.startswith(\"encoder.\")}\n",
    "encoder.load_state_dict(enc_state, strict=True)\n",
    "encoder.eval()\n",
    "\n",
    "for p in encoder.parameters():#Congelar encoder\n",
    "    p.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c465488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCNBinaryClassifier(\n",
      "  (tcn): Sequential(\n",
      "    (0): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): TemporalBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (drop1): Dropout(p=0.2, inplace=False)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (drop2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#TCN (causal) + clasificador\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size] if self.chomp_size > 0 else x\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(F.relu(self.chomp1(self.conv1(x))))\n",
    "        out = self.drop2(F.relu(self.chomp2(self.conv2(out))))\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return F.relu(out + res)\n",
    "\n",
    "class TCNBinaryClassifier(nn.Module):\n",
    "    def __init__(self, in_ch, channels=(64, 64, 64), kernel_size=3, dropout=0.2, n_classes=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch_in = in_ch\n",
    "        for i, ch_out in enumerate(channels):\n",
    "            dil = 2 ** i\n",
    "            layers.append(TemporalBlock(ch_in, ch_out, kernel_size, dil, dropout))\n",
    "            ch_in = ch_out\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(ch_in, n_classes)\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        # x_seq: (B, T, H)\n",
    "        x = x_seq.transpose(1, 2)  # (B, H, T)\n",
    "        y = self.tcn(x)            # (B, C, T)\n",
    "        last = y[:, :, -1]         # (B, C)\n",
    "        return self.fc(last)       # (B, 2)\n",
    "\n",
    "tcn_head = TCNBinaryClassifier(in_ch=H, channels=(64, 64, 64), kernel_size=3, dropout=0.2, n_classes=2).to(device)\n",
    "print(tcn_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba583d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights: [0.26901219 1.73098781]\n"
     ]
    }
   ],
   "source": [
    "#Loss + optimizer\n",
    "\n",
    "counts_w = np.bincount(y_train_w, minlength=2)\n",
    "w = 1.0 / np.maximum(counts_w, 1)\n",
    "w = w / w.sum() * 2\n",
    "class_weights = torch.tensor(w, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.02)\n",
    "\n",
    "optimizer = torch.optim.AdamW(tcn_head.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "print(\"class_weights:\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7fe067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | train loss=0.0651 acc=0.9780 | val loss=0.4243 acc=0.8662 | VAL AP(Attack)=0.9659\n",
      "Epoch 2/10 | train loss=0.0624 acc=0.9808 | val loss=0.3438 acc=0.9169 | VAL AP(Attack)=0.9797\n",
      "Epoch 3/10 | train loss=0.0598 acc=0.9835 | val loss=0.5540 acc=0.7792 | VAL AP(Attack)=0.9678\n",
      "Epoch 4/10 | train loss=0.0589 acc=0.9847 | val loss=0.7504 acc=0.7226 | VAL AP(Attack)=0.9102\n",
      "Epoch 5/10 | train loss=0.0577 acc=0.9859 | val loss=0.4225 acc=0.8695 | VAL AP(Attack)=0.9546\n",
      "Epoch 6/10 | train loss=0.0566 acc=0.9869 | val loss=0.6451 acc=0.7828 | VAL AP(Attack)=0.9285\n",
      "Epoch 7/10 | train loss=0.0552 acc=0.9882 | val loss=0.5422 acc=0.8174 | VAL AP(Attack)=0.9250\n",
      "Epoch 8/10 | train loss=0.0544 acc=0.9891 | val loss=0.6363 acc=0.7839 | VAL AP(Attack)=0.9259\n",
      "Epoch 9/10 | train loss=0.0538 acc=0.9895 | val loss=0.4411 acc=0.8692 | VAL AP(Attack)=0.9608\n",
      "Epoch 10/10 | train loss=0.0538 acc=0.9900 | val loss=0.3402 acc=0.9289 | VAL AP(Attack)=0.9606\n",
      "Best VAL AP(Attack): 0.9797489017946553\n"
     ]
    }
   ],
   "source": [
    "#Train / Eval loops \n",
    "from sklearn.metrics import average_precision_score, f1_score, balanced_accuracy_score, matthews_corrcoef\n",
    "\n",
    "def predict_proba(loader):\n",
    "    encoder.eval()\n",
    "    tcn_head.eval()\n",
    "    ys, prob_attack = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            out_seq, _ = encoder(xb)              # (B, T, H)\n",
    "            logits = tcn_head(out_seq)            # (B, 2)\n",
    "            probs = torch.softmax(logits, dim=1)  # (B, 2)\n",
    "            ys.append(yb.numpy())\n",
    "            prob_attack.append(probs[:, 1].cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    p1 = np.concatenate(prob_attack)\n",
    "    y_pred = (p1 >= 0.5).astype(np.int64)\n",
    "    return y_true, y_pred, p1\n",
    "\n",
    "def run_epoch(train=True):\n",
    "    if train:\n",
    "        tcn_head.train()\n",
    "    else:\n",
    "        tcn_head.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    loader = train_loader if train else val_loader\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            out_seq, _ = encoder(xb)\n",
    "            logits = tcn_head(out_seq)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(tcn_head.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "EPOCHS = 10\n",
    "best_val_ap = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train=True)\n",
    "    va_loss, va_acc = run_epoch(train=False)\n",
    "\n",
    "    yv, yv_pred, yv_p1 = predict_proba(val_loader)\n",
    "    val_ap = average_precision_score(yv, yv_p1)  # AP para clase Attack (positiva)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | train loss={tr_loss:.4f} acc={tr_acc:.4f} | val loss={va_loss:.4f} acc={va_acc:.4f} | VAL AP(Attack)={val_ap:.4f}\")\n",
    "\n",
    "    if val_ap > best_val_ap:\n",
    "        best_val_ap = val_ap\n",
    "        best_state = {k: v.cpu().clone() for k, v in tcn_head.state_dict().items()}\n",
    "\n",
    "print(\"Best VAL AP(Attack):\", best_val_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845abc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST metrics\n",
      "F1 macro: 0.9500247242541622\n",
      "Balanced Accuracy: 0.9644943780571436\n",
      "MCC: 0.9031149692112844\n",
      "PR-AUC (Attack): 0.9936368158235777\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9935    0.9429    0.9675     58826\n",
      "           1     0.8844    0.9861    0.9325     26087\n",
      "\n",
      "    accuracy                         0.9562     84913\n",
      "   macro avg     0.9390    0.9645    0.9500     84913\n",
      "weighted avg     0.9600    0.9562    0.9568     84913\n",
      "\n",
      "Confusion matrix:\n",
      " [[55465  3361]\n",
      " [  362 25725]]\n"
     ]
    }
   ],
   "source": [
    "#TEST (threshold=0.5)\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "\n",
    "tcn_head.load_state_dict(best_state)\n",
    "tcn_head.to(device)\n",
    "\n",
    "y_true, y_pred, p1 = predict_proba(test_loader)\n",
    "\n",
    "f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "bal_acc  = balanced_accuracy_score(y_true, y_pred)\n",
    "mcc      = matthews_corrcoef(y_true, y_pred)\n",
    "ap_attack = average_precision_score(y_true, p1)\n",
    "\n",
    "print(\"TEST metrics\")\n",
    "print(\"F1 macro:\", f1_macro)\n",
    "print(\"Balanced Accuracy:\", bal_acc)\n",
    "print(\"MCC:\", mcc)\n",
    "print(\"PR-AUC (Attack):\", ap_attack)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def252de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Curva Precision-Recall (Attack) en TEST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_true, p1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rec, prec)\n",
    "plt.title(\"Precision-Recall (Attack) - TEST\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be250666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: exports/p2_test_preds.parquet | shape: (84913, 9)\n",
      "Guardado: exports/p2_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "\n",
    "# Timestamp a nivel de flujo en TEST\n",
    "ts_test_flow = df[\"Timestamp\"].iloc[i_val:].reset_index(drop=True)\n",
    "\n",
    "# ends por ventana (índice del último elemento)\n",
    "ends = np.array(test_ds.starts) + WINDOW_SIZE - 1\n",
    "\n",
    "# timestamp de predicción por ventana = timestamp del fin de ventana\n",
    "ts_test_win = ts_test_flow.iloc[ends].reset_index(drop=True)\n",
    "\n",
    "\n",
    "p_attack = p1.astype(float)  \n",
    "\n",
    "out = pd.DataFrame({\n",
    "    \"pipeline\": \"p2_pca_gru_tcn\",\n",
    "    \"timestamp\": ts_test_win,\n",
    "    \"y_true\": y_true.astype(int),\n",
    "    \"y_pred\": y_pred.astype(int),\n",
    "    \"p_attack\": p_attack,\n",
    "    \"window_start\": np.array(test_ds.starts, dtype=int),\n",
    "    \"window_end\": ends.astype(int),\n",
    "    \"window_size\": int(WINDOW_SIZE),\n",
    "    \"stride\": int(STRIDE),\n",
    "})\n",
    "\n",
    "out.to_parquet(\"exports/p2_test_preds.parquet\", index=False)\n",
    "print(\"Guardado:\", \"exports/p2_test_preds.parquet\", \"| shape:\", out.shape)\n",
    "\n",
    "meta = {\n",
    "    \"pipeline\": \"p2_pca_gru_tcn\",\n",
    "    \"task\": \"binary\",\n",
    "    \"split\": \"temporal\",\n",
    "    \"train_frac\": 0.70,\n",
    "    \"val_frac\": 0.15,\n",
    "    \"test_frac\": 0.15,\n",
    "    \"pca_components\": int(X_train_pca.shape[1]),\n",
    "    \"gru_hidden\": 64,\n",
    "    \"window_size\": int(WINDOW_SIZE),\n",
    "    \"stride\": int(STRIDE),\n",
    "}\n",
    "with open(\"exports/p2_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, default=str)\n",
    "print(\"Guardado:\", \"exports/p2_meta.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
